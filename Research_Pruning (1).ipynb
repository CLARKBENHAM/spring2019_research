{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Research_Pruning.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyMwEI+xtIgp8eMhLyteifyj"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"53a_0B-7Tjk0","colab_type":"code","outputId":"88450f94-039a-43f8-8cc4-0448a93fdb70","executionInfo":{"status":"ok","timestamp":1589318715208,"user_tz":240,"elapsed":62725,"user":{"displayName":"Clark Benham","photoUrl":"","userId":"07053240447517243842"}},"colab":{"base_uri":"https://localhost:8080/","height":268}},"source":["import torch\n","from torch import nn\n","import torch.nn.utils.prune as prune\n","import torch.nn.functional as F\n","\n","from __future__ import print_function\n","from __future__ import division\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","import torchvision\n","from torchvision import datasets, models, transforms\n","import matplotlib.pyplot as plt\n","import time\n","import os\n","import copy\n","import pdb\n","\n","#Code in this section was taken from\n","#https://colab.research.google.com/github/pytorch/tutorials/blob/gh-pages/_downloads/finetuning_torchvision_models_tutorial.ipynb\n","\n","from google.colab import drive\n","drive.mount('/content/drive/')\n","\n","data_dir = \"/content/drive/My Drive/Research/hymenoptera_data/hymenoptera_data\"\n","\n","# Number of classes in the dataset\n","num_classes = 2\n","\n","# Batch size for training (change depending on how much memory you have)\n","batch_size = 8\n","\n","# Number of epochs to train for \n","num_epochs = 1\n","\n","# Flag for feature extracting. When False, we finetune the whole model, \n","#   when True we only update the reshaped layer params\n","feature_extract = False\n","\n","input_size = 224\n","\n","def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_pruning = False):\n","    since = time.time()\n","\n","    val_acc_history = []\n","    prune_percent = []\n","    # best_model_wts = copy.deepcopy(model.state_dict())\n","    best_acc = 0.0\n","\n","    for epoch in range(num_epochs):\n","        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n","        print('-' * 10)\n","\n","        # Each epoch has a training and validation phase\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                model.train()  # Set model to training mode\n","            else:\n","                model.eval()   # Set model to evaluate mode\n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","\n","            # Iterate over data.\n","            for ix, (inputs, labels) in enumerate(dataloaders[phase]):\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","\n","                # zero the parameter gradients\n","                optimizer.zero_grad()\n","\n","                # forward\n","                # track history if only in train\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    # Get model outputs and calculate loss\n","                    outputs = model(inputs)\n","                    loss = criterion(outputs, labels)\n","                    # backward + optimize only if in training phase\n","                    if phase == 'train':#len(dataloaders_dict[phase])-1:\n","                        loss.backward()\n","                        if is_pruning:\n","                            with torch.no_grad():\n","                                prune_buffers(model)#can't consume grads\n","                        optimizer.step()\n","                    _, preds = torch.max(outputs, 1)\n","                # statistics\n","                running_loss += loss.item() * inputs.size(0)\n","                running_corrects += torch.sum(preds == labels.data)\n","            \n","            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n","            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n","\n","            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n","\n","            # # deep copy the model\n","            if phase == 'val' and epoch_acc > best_acc:\n","                best_acc = epoch_acc\n","            #     best_model_wts = copy.deepcopy(model.state_dict())\n","            if phase == 'val':\n","                val_acc_history.append(epoch_acc)\n","\n","        print()\n","\n","    time_elapsed = time.time() - since\n","    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n","    print('Best val Acc: {:4f}'.format(best_acc))\n","\n","    # load best model weights\n","    # model.load_state_dict(best_model_wts)\n","    return val_acc_history[-1]\n","\n","data_transforms = {\n","    'train': transforms.Compose([\n","        transforms.RandomResizedCrop(input_size),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","    'val': transforms.Compose([\n","        transforms.Resize(input_size),\n","        transforms.CenterCrop(input_size),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","    'test': transforms.Compose([\n","        transforms.Resize(input_size),\n","        transforms.CenterCrop(input_size),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","}\n","\n","# Create training and validation datasets\n","image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val', 'test']}\n","# Create training and validation dataloaders\n","dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val', 'test']}\n","\n","# Detect if we have a GPU available\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","resultDevice = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n","\n","# train_model(model, dataloaders_dict, criterion, optimizer_ft, num_epochs=1)\n","print(\"\"\"Epoch 0/0\n","----------\n","train Loss: 0.5233 Acc: 0.6886\n","val Loss: 0.2095 Acc: 0.9412\n","\n","Training complete in 2m 23s\n","Best val Acc: 0.941176\n","tensor(0.9412, dtype=torch.float64)\"\"\")"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive/\n","Epoch 0/0\n","----------\n","train Loss: 0.5233 Acc: 0.6886\n","val Loss: 0.2095 Acc: 0.9412\n","\n","Training complete in 2m 23s\n","Best val Acc: 0.941176\n","tensor(0.9412, dtype=torch.float64)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Qw11IRl41eCd","outputId":"31f1ab2e-9911-4b72-9beb-8bb8e5d19b88","executionInfo":{"status":"error","timestamp":1589319707551,"user_tz":240,"elapsed":2353,"user":{"displayName":"Clark Benham","photoUrl":"","userId":"07053240447517243842"}},"colab":{"base_uri":"https://localhost:8080/","height":168}},"source":["import  torch . nn  as  nn\n","from  torchvision . models  import  vgg11_bn\n","from  collections  import  namedtuple\n","from torchsummary import summary\n","import re\n","import time\n","\n","def getLayer(model, child = 'classifier', layer_tp = nn.Linear):\n","    \"\"\"Returns indexs to all the modules of type layer_tp which are under the \n","    name 'child' in model's .chilren()\n","    Layer starts at 1 since .modules() returns ALL modules in model, the first elment of which is it's model.\n","    return  index against .children()[child], index against .modules()\n","    \"\"\"\n","    layer = 1\n","    layers = []\n","    l = float('inf')\n","    assert child in model._modules.keys(), f\"{child} is not a direct child of model, must be one of: {str(model._modules.keys())}\"\n","    for c in model.named_children():\n","        if c[0] == child:\n","            l = min(l, layer)\n","            for m in c[1].modules():\n","                if isinstance(m, layer_tp):\n","                    layers += [layer]\n","                layer += 1\n","        else:\n","        #This won't get all the sub-sub modules of network, but since those wouldn't be indexed before the target layer in nn.modules don't care\n","        #len(module_iter(c[1])) to get all sub-sub modules \n","            layer += len(list(c[1].modules()))\n","    return [i-l for i in layers], layers\n","\n","def module_iter(model):\n","    \"Get's the 'bottom most' modules of model\"\n","    if not list(model.children()):#bottom node \n","        return [model]\n","    else:\n","        return [mc for m in model.children() for mc in module_iter(m)]\n","\n","def get_buf(buf_name, model):\n","    \"Returns the buffer matching buf_name in model\"\n","    buf = next(filter(lambda i: i[0] == buf_name, model.named_buffers()))\n","    return buf[1]\n","\n","class  Vgg11bn (torch.nn.Module):\n","    \"\"\"a Vgg11 model with batch normalization and instead of 1000 predictive classes,\n","    only has 2.\n","    Buffer's attached to module that they're used to prune, regardless of if \n","    output/input to that module\n","    \"\"\"\n","\n","    def  __init__ (self, num_classes = 2, only_tune_classifier = False, numResults = batch_size):      \n","        super(). __init__ ()\n","        vgg_pre = models.vgg11_bn(pretrained=True)\n","        #self = models.vgg11_bn(pretrained=True, {'num_classes':num_classes})\n","        self.features  = copy.deepcopy(vgg_pre.features)\n","        # self.avgpool = copy.deepcopy(vgg_pre.avgpool)     \n","        self.features.add_module(\"AvgPool_Feat\", copy.deepcopy(vgg_pre.avgpool))\n","\n","        self.classifier = copy.deepcopy(vgg_pre.classifier)\n","        num_ftrs = vgg_pre.classifier[6].in_features\n","        self.classifier[6] = nn.Linear(num_ftrs,num_classes)#changes last linear layer\n","        del vgg_pre\n","        #only_tune_class when True we only update the reshaped layer params; when false we finetune the whole model, \n","        self.only_tune_classifier = only_tune_classifier\n","        if only_tune_classifier:\n","            for param in self.features.parameters():\n","                param.requires_grad = False\n","        self.numResults = numResults\n","        #select which layers to prune\n","        self.layer_prune_init()\n","        #Make Buffer's to store info for each layer\n","        self.prune_buffer_init()\n","\n","    def layer_prune_init(self):\n","        \"\"\"self.classifierPruneIx is the index of the modules used for pruning;\n","        regardless of on input/output.\n","        featuresPruneIx is based on the output of the layers (convolutional)\n","        classifierPruneIx is based on the input to the layers (Linear Layers)\n","        Both are the indexs for model under the self.feature, self.classifier\n","        PruneIx_* is the index if used .modules(), releative to full model\n","        *Module*PruneIx is the index for the index within that *Module*\n","        self.pruneNames: names of the modules which will be pruned, [\".\".join(re.findall(\"([a-zA-z]+)(\\d+)\", i)[0]) for i in self.pruneNames], convert back\n","        \"\"\"\n","        featurePruneIx, PruneIx_feature = \\\n","                getLayer(self, child='features', layer_tp = nn.Conv2d)\n","        #getayer returns indexes for .children(), .modules(); NOT the ith matching entry\n","        laterFeat = lambda i: i > 5\n","        featurePruneIx = list(filter(laterFeat, featurePruneIx))\n","        PruneIx_feature = PruneIx_feature[-len(featurePruneIx):]\n","        classifierPruneIx, PruneIx_classifier = \\\n","                        getLayer(self, child='classifier', layer_tp = nn.Linear)\n","        self.pruneLayersIx =  PruneIx_classifier#PruneIx_feature +\n","        self.featureInputIx = []\n","        self.featureOutputIx = []#[i-1 for i in featurePruneIx]\n","        self.classifierInputIx = [i-1 for i in classifierPruneIx]\n","        self.classifierOutputIx = [i-1 for i in classifierPruneIx]#, both in and output\n","        self.pruneModuleNames, self.pruneModules = zip(*[list(self.named_modules())[i]\n","                                            for i in self.pruneLayersIx])\n","        # self.pruneNames = [i.replace(\".\", \"\") for i in self.pruneNames]\n","\n","    def prune_buffer_init(self):\n","        \"\"\"Currently only sets linear layers as pruneable\n","        self.currently_pruning: dict of module name + pruning buffer type(in/out) to layer \n","        contains seperate entries for each buffer attached to the same model\n","        \"\"\"\n","        zero = torch.zeros(1, 3,224,224)\n","        self.training = False\n","        prune_out = self.forward(zero, ret_pruneLayers = True)\n","        self.currently_pruning = {}\n","        for ix, (name, tnsrS) in enumerate(prune_out.items()):\n","            for tnsr, tp in zip(tnsrS, (\"in\", \"out\")):\n","                if tnsr is not None:\n","                    shape = [self.numResults] + list(tnsr.shape)\n","                    module = self.pruneModules[ix]\n","                    module.register_buffer(\"prune_buf_\" + tp, torch.zeros(*shape))\n","                    layer_ix = self.pruneLayersIx[ix]\n","                    is_pruning = isinstance(module, nn.Linear)#GRIBB!!!!!!\n","                    self.currently_pruning[name + \".prune_buf_\" + tp] = [is_pruning, layer_ix]\n","        self.bufferCount = 0 #incremented each time buffer modified \n","\n","\n","    def  forward (self , x, ret_pruneLayers = False):\n","        \"\"\"propogates forward, with sideffect of storing the 'prune layers'\n","        ret_pruneLayers: returns intermediate pruning layers; used for init\n","        \"\"\"\n","        results = []\n","        # pdb.set_trace()\n","        for  i , model  in  enumerate(self.features):\n","            y  =  model(x)\n","            if  i  in self.featureInputIx and  i  in self.featureOutputIx:\n","                results.append((x, y))\n","            elif  i  in self.featureInputIx:\n","                results.append((x, None))\n","            elif  i  in self.featureOutputIx:\n","                results.append((None, y))\n","            x = y\n","        x = torch.flatten(x, 1)\n","        for  i , model  in  enumerate(self.classifier):\n","            #model._buffers['weight_mask'].shape\n","            y  =  model(x)\n","            # print(ii, x.shape, y.shape)\n","            if  i  in self.classifierInputIx and  i in self.classifierOutputIx:\n","                results.append((x, y))\n","            elif  i  in self.classifierInputIx:\n","                results.append((x, None))\n","            elif  i  in self.classifierOutputIx:\n","                results.append((None, y))\n","            x = y\n","        out = {n: r for n,r in zip(self.pruneModuleNames, results)}\n","        if ret_pruneLayers:\n","            return  out\n","        if self.training:\n","             for buf_name, (is_pruning, layer_ix) in self.currently_pruning.items():\n","                if is_pruning:\n","                    buffer = get_buf(buf_name, self)\n","                    if buf_name[-3:] == \"_in\":\n","                        module_name = buf_name.replace(\".prune_buf_in\", \"\")\n","                        shape =  list(out[module_name][0].shape)\n","                        newShape = [shape[0]] + [1] + shape[1:]\n","                        buffer[:shape[0]] = out[module_name][0].view(*newShape)\n","                    else:\n","                        module_name = buf_name.replace(\".prune_buf_out\", \"\")\n","                        shape =  list(out[module_name][1].shape)\n","                        newShape = [shape[0]] + [1] + shape[1:]\n","                        buffer[:shape[0]] = out[module_name][1].view(*newShape)\n","                    #since all buffer sizes passsed in at once; \n","                    #but the batch size might not evenly divide the data\n","                    #are setting batch values for a full 'update' cycle, \n","                    #since numResults = batch_size  \n","                    #grib to allow larger buffers w/ intermediate pruning\n","             self.bufferCount += 1\n","             self.bufferCount %= self.numResults\n","        return x\n","\n","    def get_params(self, buffer):\n","        return default_params\n","\n","    def critOpt(self):\n","        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","        self.to(device)\n","        criterion = nn.CrossEntropyLoss()\n","        optzer = optim.SGD(self.parameters(), lr=0.001, momentum=0.9)\n","        return criterion, optzer\n","\n","class repeatedLayerOut(prune.BasePruningMethod):\n","    \"\"\"Prune every entry that's approximitly repeated;\n","    if outputs are within epison across buffer at least propEqual% of the time\n","    \n","    #grib, instead of selecting epsilon region around median shift to select sort,\n","    get range [propEqual/2, 1-propEqual/2]? But could be clustered eg. [1,1,1,1, 5, 10] with prop = 0.3\n","    \"\"\"\n","    PRUNING_TYPE = 'unstructured'\n","    #get's returned as \"raveled\" list of unmasked entries  \n","\n","    def __init__(self, module, in_buffer, out_buffer, params):\n","        #device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","        self.module = module\n","        self.in_buffer = in_buffer #get_buf('prune_buf', module)\n","        self.out_buffer = out_buffer\n","        self.params = params\n","\n","    def compute_mask(self, tnsr, default_mask):#idx, default_mask, prevResults):\n","        \"\"\"Iteratively finds the outputs that were close in previous batches and prunes them\n","        epsilon: the numerical range in which values are considerd similar\n","        propEqual: proportion of values which are similar for output to be considered constant\n","        minMask: number of outputs which have constant neurons which will be pruned\n","        propFilter: proportion of nuerons attached to constant outputs which will be filtered\n","        retains all gradients\n","        \"\"\"   \n","        epsilon = self.params['epsilon'] #same for all layers\n","        propEqual = self.params['propEqual'] #must be greater than 0.5\n","        propFilter = self.params['propFilter'] #randomly selects the neurons to prune\n","        num_results = self.params['numResults']\n","        in_buffer = self.in_buffer\n","        out_buffer = self.out_buffer\n","        # print(\"MASK\\n\", default_mask.shape, tnsr.shape, in_buffer.shape, out_buffer.shape)\n","        in_med_value, _ = torch.median(in_buffer, dim = 0)\n","        in_buf_list = torch.split(in_buffer, 1, dim = 0)#0 dim is where were stacked along\n","        in_isSimilar = torch.sum(\n","                        torch.stack([torch.ge(a, in_med_value-epsilon/2) \n","                                    & torch.le(a, in_med_value+epsilon/2)\n","                                        for a in in_buf_list]),\n","                            0)\n","        in_areConst = in_isSimilar >= propEqual*num_results#outputs which are similar\n","        \n","        out_med_value, _ = torch.median(out_buffer, dim = 0)\n","        out_buf_list = torch.split(out_buffer, 1, dim = 0)#0 dim is where were stacked along\n","        out_isSimilar = torch.sum(\n","                        torch.stack([torch.ge(a, out_med_value-epsilon/2) \n","                                    & torch.le(a, out_med_value+epsilon/2)\n","                                        for a in out_buf_list]),\n","                            0)\n","        out_areConst = out_isSimilar >= propEqual*num_results#outputs which are similar\n","        #Get from similar outputs to neurons to be pruned\n","        if isinstance(self.module, nn.Conv2d):\n","            const_neurons = torch.grad(~areConst, self, retain_graph = True)\n","            #if is constant neuron and rand_filter = 1, then is NOT pruned\n","            mask = torch.where(const_neurons == 0, \n","                               rand_filter, \n","                               torch.ones(*default_mask.shape, dtype=bool))\n","            return mask\n","        elif isinstance(self.module, nn.Linear):\n","            #have to cast to byte then back to bool since can't take bool outerproducts \n","            module_mask = ~torch.ger(torch.squeeze(out_areConst.byte()),\n","                                     torch.squeeze(in_areConst.byte())\n","                                     ).bool()#doesn't overwieght intersection\n","            rand_filter = torch.rand(out_buffer.shape[-1],\n","                                     in_buffer.shape[-1]\n","                                     ) > propFilter\n","            mask = module_mask | rand_filter#, self.module._parameters['weight_orig'].shape\n","            if mask.shape != default_mask.shape:\n","                unpruned_ix = self.module.weight_mask.bool().view(-1)#Bad!!\n","                return mask.view(-1)[unpruned_ix]\n","            else:\n","                return mask\n","        else:\n","            print(\"Module Type not recognized: \", type(self.module))\n","\n","def prune_buffers(model):\n","    \"Calls pruning wrapper based on all buffers that have been accumulated\"\n","    param_name = 'weight'\n","    for module_name in model.pruneModuleNames:\n","        in_buf_name = module_name + '.prune_buf_in'\n","        out_buf_name = module_name + '.prune_buf_out'\n","        in_buffer = None\n","        out_buffer = None\n","        if in_buf_name in model.currently_pruning:\n","            is_pruning_in, layer_ix = model.currently_pruning[in_buf_name]\n","            in_buffer = get_buf(in_buf_name, model)\n","        else:\n","            is_pruning_in = False\n","        if out_buf_name in model.currently_pruning:\n","            is_pruning_out, layer_ix = model.currently_pruning[out_buf_name]\n","            out_buffer = get_buf(out_buf_name, model)\n","        else:\n","            is_pruning_out = False\n","\n","        if is_pruning_in or is_pruning_out:\n","            module = list(model.modules())[layer_ix]\n","            params = model.get_params(None)\n","            myPruner = repeatedLayerOut(module, in_buffer, out_buffer, params) \n","            myPruner.apply(module, \n","                           param_name,\n","                           module,#for init inside apply method\n","                           in_buffer,#apply method\n","                           out_buffer,\n","                           params\n","                           )\n","            \n","def fill_buffers(model, dataloaders = dataloaders_dict, num_passes = 1):\n","    \"fill_buffers_only: returns as soon as buffers have been filled\"\n","    for ix, (inputs, labels) in enumerate(dataloaders['train']):\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","        with torch.set_grad_enabled(True):\n","            # Get model outputs and calculate loss\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward\n","            prune_buffers(model)\n","        if (ix -1) >= num_passes:\n","            return None\n","\n","def check_accuracy(model, dataloaders = dataloaders_dict, phase='test'):\n","    \"phase in val or test\"\n","    model.eval()\n","    running_corrects = 0\n","    for ix, (inputs, labels) in enumerate(dataloaders[phase]):\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","        with torch.set_grad_enabled(False):\n","            outputs = model(inputs)\n","            _, preds = torch.max(outputs, 1)\n","            running_corrects += torch.sum(preds == labels.data)\n","    epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n","    return epoch_acc\n","\n","def total_pruned(model, print_out = False):\n","    total_prune = 0\n","    for ix, c in enumerate(model.modules()):\n","        if ix in model.pruneLayersIx:\n","            total_prune +=torch.sum(c.weight == 0)\n","            if print_out:\n","                print(ix, c, \n","                    f\"{100.0*torch.sum(c.weight == 0)/c.weight.nelement()}% Pruned\") \n","    return total_prune\n","    \n","# model = Vgg11bn()\n","# total_pruned(model, print_out = True)\n","# criterion, optimizer_ft = model.critOpt()\n","\n","print(f\"### Validation Accuracy\\\n","    ### Elements Pruned\\\n","    ### Time (Seconds)\\n\")\n","\n","within_epsilon = [1, 2, 4, 8]\n","prop_equal = [0.5, 0.60, 0.7, 0.8]\n","prop_filter = [0.1, 0.2, 0.3]\n","\n","results_untrained = torch.zeros(4,4,3)\n","pruned_untrained = torch.zeros(4,4,3)\n","time1 = torch.zeros(4,4,3)\n","max_acc_untrained = 0\n","params_untrained = None\n","untrained_model = None\n","\n","results_trained = torch.zeros(4,4,3)\n","pruned_trained = torch.zeros(4,4,3)\n","time2 = torch.zeros(4,4,3)\n","max_acc_trained = 0\n","params_trained = None\n","trained_model = None\n","\n","break\n","\n","for ie, e in enumerate(within_epsilon):\n","    for ipE, pE in enumerate(prop_equal):\n","        for ipF, pF in enumerate(prop_filter):\n","            default_params  = {'epsilon': e,\n","                                'propEqual': pE,\n","                                'propFilter': pF, \n","                                'numResults': batch_size}\n","            model = Vgg11bn()\n","            criterion, optimizer_ft = model.critOpt()\n","            a = time.time()\n","            results_trained[ie, ipE, ipF] = train_model(model, \n","                                                        dataloaders_dict, \n","                                                        criterion, \n","                                                        optimizer_ft,\n","                                                        num_epochs=1,\n","                                                        is_pruning = True)\n","            time2[ie, ipE, ipF] = time.time() - a\n","            pruned_trained[ie, ipE, ipF] = total_pruned(model, print_out=True)\n","            if max_acc_trained < results_trained[ie, ipE, ipF]:\n","                max_acc_trained = results_trained[ie, ipE, ipF]\n","                params_trained = default_params\n","                trained_model = model\n","            print(f\"### {results_trained[ie, ipE, ipF]:.2f}\\\n","                ### {pruned_trained[ie, ipE, ipF]:.2f}\\\n","                ### {time2[ie, ipE, ipF]:.2f}\\n\")\n","            del model\n","\n","print(\"%%%%%%%End trained%%%%%%%\\n\\n\\n\\n$$$$$Start Untrained$$$$$\")\n","\n","\n","for ie, e in enumerate(within_epsilon):\n","    for ipE, pE in enumerate(prop_equal):\n","        for ipF, pF in enumerate(prop_filter):\n","            default_params  = {'epsilon': e,\n","                            'propEqual': pE,\n","                            'propFilter': pF, \n","                            'numResults': batch_size}\n","            model = Vgg11bn()\n","            criterion, optimizer_ft = model.critOpt()\n","            a = time.time()\n","            fill_buffers(model, num_passes=4)\n","            results_untrained[ie, ipE, ipF] = check_accuracy(model, phase='val')\n","            time1[ie, ipE, ipF] = time.time() - a\n","            pruned_untrained[ie, ipE, ipF] = total_pruned(model, print_out=True)\n","\n","            if max_acc_untrained < results_untrained[ie, ipE, ipF]:\n","                max_acc_untrained = results_untrained[ie, ipE, ipF]\n","                params_untrained = default_params\n","                # untrained_model = model\n","            print(f\"### {results_untrained[ie, ipE, ipF]:.2f}\\\n","                    ### {pruned_untrained[ie, ipE, ipF]:.2f}\\\n","                    ### {time1[ie, ipE, ipF]:.2f}\\n\\n\")\n","            del model\n"],"execution_count":9,"outputs":[{"output_type":"stream","text":["### Validation Accuracy    ### Elements Pruned    ### Time (Seconds)\n","\n"],"name":"stdout"},{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-19e3bc203aef>\"\u001b[0;36m, line \u001b[0;32m351\u001b[0m\n\u001b[0;31m    break\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'break' outside loop\n"]}]},{"cell_type":"code","metadata":{"id":"oNymFzjwugwA","colab_type":"code","colab":{},"cellView":"form"},"source":["#@title\n","s = \"\"\"33 Linear(in_features=25088, out_features=4096, bias=True) 46.86307144165039% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 46.8585205078125% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 47.509765625% Pruned\n","### 0.48                    ### 56022152.00                    ### 82.85\n","\n","\n","33 Linear(in_features=25088, out_features=4096, bias=True) 73.7840576171875% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 73.79650115966797% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 73.876953125% Pruned\n","### 0.46                    ### 88207872.00                    ### 80.40\n","\n","\n","33 Linear(in_features=25088, out_features=4096, bias=True) 88.2318344116211% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 88.23563385009766% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 88.34228515625% Pruned\n","### 0.46                    ### 105478144.00                    ### 73.65\n","\n","\n","33 Linear(in_features=25088, out_features=4096, bias=True) 46.851566314697266% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 46.86142349243164% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 46.6552734375% Pruned\n","### 0.40                    ### 56010744.00                    ### 77.72\n","\n","\n","33 Linear(in_features=25088, out_features=4096, bias=True) 73.7934799194336% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 73.79026794433594% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 73.5107421875% Pruned\n","### 0.41                    ### 88216480.00                    ### 74.90\n","\n","\n","33 Linear(in_features=25088, out_features=4096, bias=True) 88.23404693603516% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 88.23883819580078% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 88.09814453125% Pruned\n","### 0.54                    ### 105480944.00                    ### 70.58\n","\n","\n","33 Linear(in_features=25088, out_features=4096, bias=True) 46.853515625% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 46.863895416259766% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 46.3134765625% Pruned\n","### 0.62                    ### 56013128.00                    ### 76.86\n","\n","\n","33 Linear(in_features=25088, out_features=4096, bias=True) 73.78302001953125% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 73.78704071044922% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 73.2666015625% Pruned\n","### 0.34                    ### 88205184.00                    ### 75.37\n","\n","\n","33 Linear(in_features=25088, out_features=4096, bias=True) 88.23873901367188% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 88.24845886230469% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 88.36669921875% Pruned\n","### 0.54                    ### 105487400.00                    ### 71.41\n","\n","\n","33 Linear(in_features=25088, out_features=4096, bias=True) 46.852508544921875% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 46.86733627319336% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 46.49658203125% Pruned\n","### 0.44                    ### 56012692.00                    ### 84.37\n","\n","\n","33 Linear(in_features=25088, out_features=4096, bias=True) 73.79354858398438% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 73.8038330078125% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 74.06005859375% Pruned\n","### 0.56                    ### 88218880.00                    ### 76.57\n","\n","\n","33 Linear(in_features=25088, out_features=4096, bias=True) 88.23758697509766% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 88.23320007324219% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 87.97607421875% Pruned\n","### 0.45                    ### 105483616.00                    ### 71.62\n","\n","\n","33 Linear(in_features=25088, out_features=4096, bias=True) 46.85257339477539% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 46.87030792236328% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 46.533203125% Pruned\n","### 0.59                    ### 56013264.00                    ### 76.75\n","\n","\n","33 Linear(in_features=25088, out_features=4096, bias=True) 73.78116607666016% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 73.78683471679688% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 74.76806640625% Pruned\n","### 0.44                    ### 88203360.00                    ### 74.86\n","\n","\n","33 Linear(in_features=25088, out_features=4096, bias=True) 88.23784637451172% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 88.23371887207031% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 88.6474609375% Pruned\n","### 0.54                    ### 105484024.00                    ### 70.32\n","\n","\n","33 Linear(in_features=25088, out_features=4096, bias=True) 46.85880661010742% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 46.84529113769531% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 47.4853515625% Pruned\n","### 0.42                    ### 56015548.00                    ### 76.19\n","\n","\n","33 Linear(in_features=25088, out_features=4096, bias=True) 73.7872085571289% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 73.77244567871094% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 74.0966796875% Pruned\n","### 0.54                    ### 88207096.00                    ### 74.50\n","\n","\n","33 Linear(in_features=25088, out_features=4096, bias=True) 88.23336791992188% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 88.22205352783203% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 88.70849609375% Pruned\n","### 0.54                    ### 105477472.00                    ### 71.61\n","\n","\n","33 Linear(in_features=25088, out_features=4096, bias=True) 46.86458206176758% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 46.8434944152832% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 46.39892578125% Pruned\n","### 0.37                    ### 56021092.00                    ### 76.76\n","\n","\n","33 Linear(in_features=25088, out_features=4096, bias=True) 73.79022216796875% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 73.78691864013672% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 73.91357421875% Pruned\n","### 0.54                    ### 88212608.00                    ### 74.34\n","\n","\n","33 Linear(in_features=25088, out_features=4096, bias=True) 88.23995208740234% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 88.22856903076172% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 88.73291015625% Pruned\n","### 0.46                    ### 105485336.00                    ### 70.56\n","\n","\n","33 Linear(in_features=25088, out_features=4096, bias=True) 46.85671615600586% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 46.86176300048828% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 46.93603515625% Pruned\n","### 0.45                    ### 56016116.00                    ### 77.67\n","\n","\n","33 Linear(in_features=25088, out_features=4096, bias=True) 73.79084777832031% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 73.7819595336914% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 73.47412109375% Pruned\n","### 0.68                    ### 88212384.00                    ### 75.16\n","\n","\n","33 Linear(in_features=25088, out_features=4096, bias=True) 88.24044036865234% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 88.25282287597656% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 86.80419921875% Pruned\n","### 0.46                    ### 105489760.00                    ### 70.89\n","\n","\n","33 Linear(in_features=25088, out_features=4096, bias=True) 46.854862213134766% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 46.84408187866211% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 46.1181640625% Pruned\n","### 0.53                    ### 56011176.00                    ### 76.82\n","\n","\n","33 Linear(in_features=25088, out_features=4096, bias=True) 73.78094482421875% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 73.78980255126953% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 73.79150390625% Pruned\n","### 0.52                    ### 88203552.00                    ### 76.14\n","\n","\n","33 Linear(in_features=25088, out_features=4096, bias=True) 88.23804473876953% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 88.2342529296875% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 88.5498046875% Pruned\n","### 0.54                    ### 105484312.00                    ### 71.10\n","\n","\n","33 Linear(in_features=25088, out_features=4096, bias=True) 46.86110305786133% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 46.8686408996582% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 46.3623046875% Pruned\n","### 0.41                    ### 56021732.00                    ### 77.24\n","\n","\n","33 Linear(in_features=25088, out_features=4096, bias=True) 73.7739028930664% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 73.7862548828125% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 73.53515625% Pruned\n","### 0.48                    ### 88195696.00                    ### 74.54\n","\n","\n","33 Linear(in_features=25088, out_features=4096, bias=True) 88.23578643798828% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 88.24055480957031% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 88.525390625% Pruned\n","### 0.46                    ### 105483056.00                    ### 70.59\n","\n","\n","33 Linear(in_features=25088, out_features=4096, bias=True) 46.85675811767578% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 46.83415222167969% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 46.7041015625% Pruned\n","### 0.55                    ### 56011508.00                    ### 76.31\n","\n","\n","33 Linear(in_features=25088, out_features=4096, bias=True) 73.7848892211914% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 73.78089141845703% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 73.388671875% Pruned\n","### 0.49                    ### 88206072.00                    ### 74.34\n","\n","\n","33 Linear(in_features=25088, out_features=4096, bias=True) 88.23382568359375% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 88.2318344116211% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 87.8662109375% Pruned\n","### 0.54                    ### 105479520.00                    ### 70.11\n","\n","\n","33 Linear(in_features=25088, out_features=4096, bias=True) 46.86415481567383% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 46.850196838378906% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 46.22802734375% Pruned\n","### 0.56                    ### 56021760.00                    ### 77.33\n","\n","\n","33 Linear(in_features=25088, out_features=4096, bias=True) 73.78787994384766% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 73.78739929199219% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 73.193359375% Pruned\n","### 0.55                    ### 88210216.00                    ### 75.28\n","\n","\n","33 Linear(in_features=25088, out_features=4096, bias=True) 88.2351303100586% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 88.23873138427734% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 87.85400390625% Pruned\n","### 0.65                    ### 105482016.00                    ### 70.43\n","\n","\n","33 Linear(in_features=25088, out_features=4096, bias=True) 46.85382843017578% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 46.84412384033203% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 47.412109375% Pruned\n","### 0.31                    ### 56010228.00                    ### 76.66\n","\n","\n","33 Linear(in_features=25088, out_features=4096, bias=True) 73.78926086425781% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 73.78945922851562% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 72.59521484375% Pruned\n","### 0.45                    ### 88211944.00                    ### 75.11\n","\n","\n","33 Linear(in_features=25088, out_features=4096, bias=True) 88.23656463623047% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 88.24127197265625% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 87.744140625% Pruned\n","### 0.55                    ### 105483904.00                    ### 71.04\n","\n","\n","33 Linear(in_features=25088, out_features=4096, bias=True) 46.85751724243164% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 46.860416412353516% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 47.44873046875% Pruned\n","### 0.45                    ### 56016752.00                    ### 76.48\n","\n","\n","33 Linear(in_features=25088, out_features=4096, bias=True) 73.78726196289062% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 73.7730941772461% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 73.64501953125% Pruned\n","### 0.48                    ### 88207224.00                    ### 75.11\n","\n","\n","33 Linear(in_features=25088, out_features=4096, bias=True) 88.23760223388672% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 88.23046112060547% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 87.98828125% Pruned\n","### 0.55                    ### 105483176.00                    ### 71.34\n","\n","\n","33 Linear(in_features=25088, out_features=4096, bias=True) 46.8482780456543% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 46.87440872192383% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 45.69091796875% Pruned\n","### 0.54                    ### 56009464.00                    ### 77.11\n","\n","\n","33 Linear(in_features=25088, out_features=4096, bias=True) 73.7865982055664% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 73.79535675048828% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 74.365234375% Pruned\n","### 0.46                    ### 88210336.00                    ### 75.35\n","\n","\n","33 Linear(in_features=25088, out_features=4096, bias=True) 88.2386703491211% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 88.23358154296875% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 88.7939453125% Pruned\n","### 0.46                    ### 105484864.00                    ### 70.44\n","\n","\n","33 Linear(in_features=25088, out_features=4096, bias=True) 46.859500885009766% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 46.862518310546875% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 46.6552734375% Pruned\n","### 0.44                    ### 56019080.00                    ### 77.07\n","\n","\n","33 Linear(in_features=25088, out_features=4096, bias=True) 73.78606414794922% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 73.77337646484375% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 74.03564453125% Pruned\n","### 0.46                    ### 88206072.00                    ### 75.73\n","\n","\n","33 Linear(in_features=25088, out_features=4096, bias=True) 88.2383804321289% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 88.23115539550781% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 88.85498046875% Pruned\n","### 0.54                    ### 105484176.00                    ### 71.29\"\"\"\n","\n","s2 = \"\"\"Epoch 0/0\n","----------\n","train Loss: 0.6804 Acc: 0.6140\n","val Loss: 0.6935 Acc: 0.4575\n","\n","Training complete in 5m 2s\n","Best val Acc: 0.457516\n","33 Linear(in_features=25088, out_features=4096, bias=True) 95.28697967529297% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 95.28395080566406% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 95.5078125% Pruned\n","### 0.46                ### 113911144.00                ### 301.97\n","\n","Epoch 0/0\n","----------\n","train Loss: 0.6965 Acc: 0.5000\n","val Loss: 0.6935 Acc: 0.4575\n","\n","Training complete in 4m 23s\n","Best val Acc: 0.457516\n","33 Linear(in_features=25088, out_features=4096, bias=True) 99.84536743164062% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 99.84488677978516% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 99.84130859375% Pruned\n","### 0.46                ### 119360912.00                ### 262.70\n","\n","Epoch 0/0\n","----------\n","train Loss: 0.6965 Acc: 0.4868\n","val Loss: 0.6926 Acc: 0.5425\n","\n","Training complete in 4m 14s\n","Best val Acc: 0.542484\n","33 Linear(in_features=25088, out_features=4096, bias=True) 99.9967041015625% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 99.99674987792969% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 100.0% Pruned\n","### 0.54                ### 119541920.00                ### 253.65\n","\n","Epoch 0/0\n","----------\n","train Loss: 0.6919 Acc: 0.5877\n","val Loss: 0.6929 Acc: 0.5425\n","\n","Training complete in 4m 55s\n","Best val Acc: 0.542484\n","33 Linear(in_features=25088, out_features=4096, bias=True) 95.25799560546875% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 95.23308563232422% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 95.4345703125% Pruned\n","### 0.54                ### 113872824.00                ### 295.10\n","\n","Epoch 0/0\n","----------\n","train Loss: 0.7002 Acc: 0.4737\n","val Loss: 0.6939 Acc: 0.4575\n","\n","Training complete in 4m 26s\n","Best val Acc: 0.457516\n","33 Linear(in_features=25088, out_features=4096, bias=True) 99.84182739257812% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 99.84190368652344% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 99.8291015625% Pruned\n","### 0.46                ### 119356768.00                ### 265.86\n","\n","Epoch 0/0\n","----------\n","train Loss: 0.6935 Acc: 0.4825\n","val Loss: 0.6936 Acc: 0.4575\n","\n","Training complete in 4m 12s\n","Best val Acc: 0.457516\n","33 Linear(in_features=25088, out_features=4096, bias=True) 99.99674224853516% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 99.99671936035156% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 100.0% Pruned\n","### 0.46                ### 119541952.00                ### 252.46\n","\n","Epoch 0/0\n","----------\n","train Loss: 0.6930 Acc: 0.5132\n","val Loss: 0.6914 Acc: 0.5425\n","\n","Training complete in 4m 59s\n","Best val Acc: 0.542484\n","33 Linear(in_features=25088, out_features=4096, bias=True) 94.82119750976562% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 94.88768005371094% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 94.6044921875% Pruned\n","### 0.54                ### 113365952.00                ### 299.17\n","\n","Epoch 0/0\n","----------\n","train Loss: 0.7000 Acc: 0.4781\n","val Loss: 0.6937 Acc: 0.4575\n","\n","Training complete in 4m 24s\n","Best val Acc: 0.457516\n","33 Linear(in_features=25088, out_features=4096, bias=True) 99.80309295654297% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 99.8256607055664% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 99.81689453125% Pruned\n","### 0.46                ### 119314248.00                ### 263.88\n","\n","Epoch 0/0\n","----------\n","train Loss: 0.6966 Acc: 0.5263\n","val Loss: 0.6922 Acc: 0.5425\n","\n","Training complete in 4m 12s\n","Best val Acc: 0.542484\n","33 Linear(in_features=25088, out_features=4096, bias=True) 99.99495697021484% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 99.9966049194336% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 100.0% Pruned\n","### 0.54                ### 119540104.00                ### 252.27\n","\n","Epoch 0/0\n","----------\n","train Loss: 0.6211 Acc: 0.7368\n","val Loss: 0.6746 Acc: 0.5425\n","\n","Training complete in 5m 20s\n","Best val Acc: 0.542484\n","33 Linear(in_features=25088, out_features=4096, bias=True) 90.34745025634766% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 90.93275451660156% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 89.75830078125% Pruned\n","### 0.54                ### 108104776.00                ### 319.68\n","\n","Epoch 0/0\n","----------\n","train Loss: 0.6824 Acc: 0.5307\n","val Loss: 0.6928 Acc: 0.5425\n","\n","Training complete in 4m 37s\n","Best val Acc: 0.542484\n","33 Linear(in_features=25088, out_features=4096, bias=True) 99.30992889404297% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 99.64393615722656% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 99.62158203125% Pruned\n","### 0.54                ### 118776968.00                ### 276.50\n","\n","Epoch 0/0\n","----------\n","train Loss: 0.6903 Acc: 0.4781\n","val Loss: 0.6932 Acc: 0.4575\n","\n","Training complete in 4m 21s\n","Best val Acc: 0.457516\n","33 Linear(in_features=25088, out_features=4096, bias=True) 99.93717193603516% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 99.98912048339844% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 99.96337890625% Pruned\n","### 0.46                ### 119479464.00                ### 260.75\n","\n","Epoch 0/0\n","----------\n","train Loss: 0.6907 Acc: 0.5044\n","val Loss: 0.6956 Acc: 0.4575\n","\n","Training complete in 4m 56s\n","Best val Acc: 0.457516\n","33 Linear(in_features=25088, out_features=4096, bias=True) 95.29124450683594% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 95.28609466552734% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 95.41015625% Pruned\n","### 0.46                ### 113915880.00                ### 295.60\n","\n","Epoch 0/0\n","----------\n","train Loss: 0.6970 Acc: 0.4781\n","val Loss: 0.6936 Acc: 0.4575\n","\n","Training complete in 4m 29s\n","Best val Acc: 0.457516\n","33 Linear(in_features=25088, out_features=4096, bias=True) 99.84538269042969% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 99.8441390991211% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 99.76806640625% Pruned\n","### 0.46                ### 119360800.00                ### 268.59\n","\n","Epoch 0/0\n","----------\n","train Loss: 0.6953 Acc: 0.5088\n","val Loss: 0.6945 Acc: 0.4575\n","\n","Training complete in 4m 11s\n","Best val Acc: 0.457516\n","33 Linear(in_features=25088, out_features=4096, bias=True) 99.99681854248047% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 99.99685668945312% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 100.0% Pruned\n","### 0.46                ### 119542064.00                ### 251.46\n","\n","Epoch 0/0\n","----------\n","train Loss: 0.6896 Acc: 0.5044\n","val Loss: 0.6931 Acc: 0.4575\n","\n","Training complete in 4m 55s\n","Best val Acc: 0.457516\n","33 Linear(in_features=25088, out_features=4096, bias=True) 95.28926086425781% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 95.2913818359375% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 95.39794921875% Pruned\n","### 0.46                ### 113914728.00                ### 294.74\n","\n","Epoch 0/0\n","----------\n","train Loss: 0.6891 Acc: 0.5482\n","val Loss: 0.6939 Acc: 0.4575\n","\n","Training complete in 4m 26s\n","Best val Acc: 0.457516\n","33 Linear(in_features=25088, out_features=4096, bias=True) 99.84538269042969% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 99.84619140625% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 99.86572265625% Pruned\n","### 0.46                ### 119361152.00                ### 265.82\n","\n","Epoch 0/0\n","----------\n","train Loss: 0.6953 Acc: 0.4737\n","val Loss: 0.6938 Acc: 0.4575\n","\n","Training complete in 4m 16s\n","Best val Acc: 0.457516\n","33 Linear(in_features=25088, out_features=4096, bias=True) 99.99684143066406% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 99.99657440185547% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 100.0% Pruned\n","### 0.46                ### 119542032.00                ### 255.51\n","\n","Epoch 0/0\n","----------\n","train Loss: 0.6892 Acc: 0.4956\n","val Loss: 0.6933 Acc: 0.4575\n","\n","Training complete in 4m 54s\n","Best val Acc: 0.457516\n","33 Linear(in_features=25088, out_features=4096, bias=True) 95.26688385009766% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 95.26675415039062% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 95.2880859375% Pruned\n","### 0.46                ### 113887584.00                ### 293.94\n","\n","Epoch 0/0\n","----------\n","train Loss: 0.6955 Acc: 0.5044\n","val Loss: 0.6930 Acc: 0.5425\n","\n","Training complete in 4m 32s\n","Best val Acc: 0.542484\n","33 Linear(in_features=25088, out_features=4096, bias=True) 99.84333038330078% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 99.84467315673828% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 99.81689453125% Pruned\n","### 0.54                ### 119358792.00                ### 271.60\n","\n","Epoch 0/0\n","----------\n","train Loss: 0.6914 Acc: 0.4430\n","val Loss: 0.6932 Acc: 0.4575\n","\n","Training complete in 4m 17s\n","Best val Acc: 0.457516\n","33 Linear(in_features=25088, out_features=4096, bias=True) 99.99665832519531% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 99.99658203125% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 100.0% Pruned\n","### 0.46                ### 119541856.00                ### 256.57\n","\n","Epoch 0/0\n","----------\n","train Loss: 0.6860 Acc: 0.5877\n","val Loss: 0.6927 Acc: 0.6471\n","\n","Training complete in 4m 55s\n","Best val Acc: 0.647059\n","33 Linear(in_features=25088, out_features=4096, bias=True) 94.87027740478516% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 95.01087951660156% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 95.3125% Pruned\n","### 0.65                ### 113437112.00                ### 294.57\n","\n","Epoch 0/0\n","----------\n","train Loss: 0.6912 Acc: 0.4649\n","val Loss: 0.6934 Acc: 0.4575\n","\n","Training complete in 4m 26s\n","Best val Acc: 0.457516\n","33 Linear(in_features=25088, out_features=4096, bias=True) 99.81127166748047% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 99.831298828125% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 99.90234375% Pruned\n","### 0.46                ### 119323616.00                ### 266.07\n","\n","Epoch 0/0\n","----------\n","train Loss: 0.6978 Acc: 0.4781\n","val Loss: 0.6923 Acc: 0.5425\n","\n","Training complete in 4m 13s\n","Best val Acc: 0.542484\n","33 Linear(in_features=25088, out_features=4096, bias=True) 99.99501037597656% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 99.99641418457031% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 100.0% Pruned\n","### 0.54                ### 119540120.00                ### 252.51\n","\n","Epoch 0/0\n","----------\n","train Loss: 0.6805 Acc: 0.5921\n","val Loss: 0.6949 Acc: 0.4575\n","\n","Training complete in 4m 54s\n","Best val Acc: 0.457516\n","33 Linear(in_features=25088, out_features=4096, bias=True) 95.28924560546875% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 95.2918930053711% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 95.42236328125% Pruned\n","### 0.46                ### 113914792.00                ### 293.97\n","\n","Epoch 0/0\n","----------\n","train Loss: 0.6973 Acc: 0.5000\n","val Loss: 0.6938 Acc: 0.4575\n","\n","Training complete in 4m 24s\n","Best val Acc: 0.457516\n","33 Linear(in_features=25088, out_features=4096, bias=True) 99.84489440917969% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 99.84407043457031% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 99.8291015625% Pruned\n","### 0.46                ### 119360296.00                ### 263.72\n","\n","Epoch 0/0\n","----------\n","train Loss: 0.6966 Acc: 0.5000\n","val Loss: 0.6928 Acc: 0.5425\n","\n","Training complete in 4m 13s\n","Best val Acc: 0.542484\n","33 Linear(in_features=25088, out_features=4096, bias=True) 99.99681854248047% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 99.99675750732422% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 100.0% Pruned\n","### 0.54                ### 119542048.00                ### 253.32\n","\n","Epoch 0/0\n","----------\n","train Loss: 0.6882 Acc: 0.5439\n","val Loss: 0.6942 Acc: 0.4575\n","\n","Training complete in 4m 55s\n","Best val Acc: 0.457516\n","33 Linear(in_features=25088, out_features=4096, bias=True) 95.28770446777344% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 95.29801177978516% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 95.34912109375% Pruned\n","### 0.46                ### 113914240.00                ### 295.37\n","\n","Epoch 0/0\n","----------\n","train Loss: 0.6933 Acc: 0.5175\n","val Loss: 0.6936 Acc: 0.4575\n","\n","Training complete in 4m 25s\n","Best val Acc: 0.457516\n","33 Linear(in_features=25088, out_features=4096, bias=True) 99.8459243774414% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 99.84550476074219% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 99.8046875% Pruned\n","### 0.46                ### 119361592.00                ### 265.02\n","\n","Epoch 0/0\n","----------\n","train Loss: 0.6944 Acc: 0.4737\n","val Loss: 0.6936 Acc: 0.4575\n","\n","Training complete in 4m 12s\n","Best val Acc: 0.457516\n","33 Linear(in_features=25088, out_features=4096, bias=True) 99.99667358398438% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 99.9970474243164% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 99.98779296875% Pruned\n","### 0.46                ### 119541936.00                ### 251.76\n","\n","Epoch 0/0\n","----------\n","train Loss: 0.6912 Acc: 0.5614\n","val Loss: 0.6924 Acc: 0.5425\n","\n","Training complete in 4m 55s\n","Best val Acc: 0.542484\n","33 Linear(in_features=25088, out_features=4096, bias=True) 95.2898178100586% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 95.28968048095703% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 95.1416015625% Pruned\n","### 0.54                ### 113915000.00                ### 294.65\n","\n","Epoch 0/0\n","----------\n","train Loss: 0.6946 Acc: 0.5088\n","val Loss: 0.6938 Acc: 0.4575\n","\n","Training complete in 4m 27s\n","Best val Acc: 0.457516\n","33 Linear(in_features=25088, out_features=4096, bias=True) 99.84547424316406% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 99.84436798095703% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 99.67041015625% Pruned\n","### 0.46                ### 119360928.00                ### 266.99\n","\n","Epoch 0/0\n","----------\n","train Loss: 0.6919 Acc: 0.4605\n","val Loss: 0.6940 Acc: 0.4575\n","\n","Training complete in 4m 12s\n","Best val Acc: 0.457516\n","33 Linear(in_features=25088, out_features=4096, bias=True) 99.99681854248047% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 99.99693298339844% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 100.0% Pruned\n","### 0.46                ### 119542080.00                ### 252.31\n","\n","Epoch 0/0\n","----------\n","train Loss: 0.6957 Acc: 0.4781\n","val Loss: 0.6943 Acc: 0.4575\n","\n","Training complete in 4m 56s\n","Best val Acc: 0.457516\n","33 Linear(in_features=25088, out_features=4096, bias=True) 95.27536010742188% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 95.28797149658203% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 94.970703125% Pruned\n","### 0.46                ### 113899832.00                ### 295.58\n","\n","Epoch 0/0\n","----------\n","train Loss: 0.6931 Acc: 0.4781\n","val Loss: 0.6938 Acc: 0.4575\n","\n","Training complete in 4m 25s\n","Best val Acc: 0.457516\n","33 Linear(in_features=25088, out_features=4096, bias=True) 99.84431457519531% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 99.84562683105469% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 99.8779296875% Pruned\n","### 0.46                ### 119359960.00                ### 264.91\n","\n","Epoch 0/0\n","----------\n","train Loss: 0.6944 Acc: 0.5044\n","val Loss: 0.6929 Acc: 0.5425\n","\n","Training complete in 4m 14s\n","Best val Acc: 0.542484\n","33 Linear(in_features=25088, out_features=4096, bias=True) 99.99677276611328% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 99.9969253540039% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 99.98779296875% Pruned\n","### 0.54                ### 119542024.00                ### 253.80\n","\n","Epoch 0/0\n","----------\n","train Loss: 0.6854 Acc: 0.5658\n","val Loss: 0.6934 Acc: 0.4575\n","\n","Training complete in 4m 59s\n","Best val Acc: 0.457516\n","33 Linear(in_features=25088, out_features=4096, bias=True) 95.28684997558594% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 95.28763580322266% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 95.30029296875% Pruned\n","### 0.46                ### 113911608.00                ### 298.66\n","\n","Epoch 0/0\n","----------\n","train Loss: 0.6892 Acc: 0.5263\n","val Loss: 0.6926 Acc: 0.5425\n","\n","Training complete in 4m 28s\n","Best val Acc: 0.542484\n","33 Linear(in_features=25088, out_features=4096, bias=True) 99.84467315673828% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 99.84490203857422% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 99.81689453125% Pruned\n","### 0.54                ### 119360216.00                ### 268.38\n","\n","Epoch 0/0\n","----------\n","train Loss: 0.6927 Acc: 0.5000\n","val Loss: 0.6926 Acc: 0.5425\n","\n","Training complete in 4m 14s\n","Best val Acc: 0.542484\n","33 Linear(in_features=25088, out_features=4096, bias=True) 99.99671173095703% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 99.99666595458984% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 100.0% Pruned\n","### 0.54                ### 119541920.00                ### 253.83\n","\n","Epoch 0/0\n","----------\n","train Loss: 0.6859 Acc: 0.5219\n","val Loss: 0.6934 Acc: 0.4575\n","\n","Training complete in 4m 56s\n","Best val Acc: 0.457516\n","33 Linear(in_features=25088, out_features=4096, bias=True) 95.29088592529297% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 95.29882049560547% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 95.03173828125% Pruned\n","### 0.46                ### 113917616.00                ### 296.34\n","\n","Epoch 0/0\n","----------\n","train Loss: 0.6977 Acc: 0.4737\n","val Loss: 0.6931 Acc: 0.5425\n","\n","Training complete in 4m 37s\n","Best val Acc: 0.542484\n","33 Linear(in_features=25088, out_features=4096, bias=True) 99.84465789794922% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 99.84480285644531% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 99.8046875% Pruned\n","### 0.54                ### 119360176.00                ### 276.91\n","\n","Epoch 0/0\n","----------\n","train Loss: 0.6919 Acc: 0.4868\n","val Loss: 0.6935 Acc: 0.4575\n","\n","Training complete in 4m 14s\n","Best val Acc: 0.457516\n","33 Linear(in_features=25088, out_features=4096, bias=True) 99.99674224853516% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 99.99674224853516% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 99.98779296875% Pruned\n","### 0.46                ### 119541968.00                ### 253.97\n","\n","Epoch 0/0\n","----------\n","train Loss: 0.6909 Acc: 0.5965\n","val Loss: 0.6924 Acc: 0.5425\n","\n","Training complete in 4m 54s\n","Best val Acc: 0.542484\n","33 Linear(in_features=25088, out_features=4096, bias=True) 95.28970336914062% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 95.28330993652344% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 95.66650390625% Pruned\n","### 0.54                ### 113913840.00                ### 294.41\n","\n","Epoch 0/0\n","----------\n","train Loss: 0.6921 Acc: 0.4912\n","val Loss: 0.6928 Acc: 0.5425\n","\n","Training complete in 4m 29s\n","Best val Acc: 0.542484\n","33 Linear(in_features=25088, out_features=4096, bias=True) 99.84536743164062% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 99.84416198730469% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 99.8291015625% Pruned\n","### 0.54                ### 119360792.00                ### 268.70\n","\n","Epoch 0/0\n","----------\n","train Loss: 0.7026 Acc: 0.4737\n","val Loss: 0.6926 Acc: 0.5425\n","\n","Training complete in 4m 15s\n","Best val Acc: 0.542484\n","33 Linear(in_features=25088, out_features=4096, bias=True) 99.99681091308594% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 99.99693298339844% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 100.0% Pruned\n","### 0.54                ### 119542064.00                ### 254.89\n","\n","Epoch 0/0\n","----------\n","train Loss: 0.6875 Acc: 0.5263\n","val Loss: 0.6925 Acc: 0.5425\n","\n","Training complete in 4m 55s\n","Best val Acc: 0.542484\n","33 Linear(in_features=25088, out_features=4096, bias=True) 95.2888412475586% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 95.2926254272461% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 95.556640625% Pruned\n","### 0.54                ### 113914520.00                ### 295.08\n","\n","Epoch 0/0\n","----------\n","train Loss: 0.6926 Acc: 0.5044\n","val Loss: 0.6927 Acc: 0.5425\n","\n","Training complete in 4m 28s\n","Best val Acc: 0.542484\n","33 Linear(in_features=25088, out_features=4096, bias=True) 99.84564208984375% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 99.8451156616211% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 99.8046875% Pruned\n","### 0.54                ### 119361240.00                ### 268.18\n","\n","Epoch 0/0\n","----------\n","train Loss: 0.6893 Acc: 0.5570\n","val Loss: 0.6930 Acc: 0.5425\n","\n","Training complete in 4m 34s\n","Best val Acc: 0.542484\n","33 Linear(in_features=25088, out_features=4096, bias=True) 99.9967041015625% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 99.99678802490234% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 99.98779296875% Pruned\n","### 0.54                ### 119541920.00                ### 274.26\"\"\"\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pDksWNw60MZM","colab_type":"code","colab":{}},"source":["\n","# results_untrained = torch.zeros(4,4,3)\n","# pruned_untrained = torch.zeros(4,4,3)\n","# time1 = torch.zeros(4,4,3)\n","# results_trained = torch.zeros(4,4,3)\n","# pruned_trained = torch.zeros(4,4,3)\n","# time2 = torch.zeros(4,4,3)\n","\n","# max_acc_untrained = 0\n","# params_untrained = None\n","# untrained_model = None\n","\n","sl = s.split(\"\\n\\n\\n\")\n","\n","i = 0 \n","levels = []\n","for ie, e in enumerate(within_epsilon):\n","    # i = ie*12\n","    for ipE, pE in enumerate(prop_equal):\n","        for ipF, pF in enumerate(prop_filter):\n","            sub = sl[i].split(\"\\n\")[-1]\n","            sb = re.findall(\"(\\d+\\.\\d*)\", sub)\n","            results_untrained[ie, ipE, ipF] = float(sb[0])\n","            pruned_untrained[ie, ipE, ipF] = float(sb[1])\n","            time1[ie, ipE, ipF] = float(sb[2])\n","            levels.append([float(i) for i in re.findall(\"\"\"(\\d*\\.\\d*)\\% Pruned\"\"\", sl[i])])\n","            i += 1\n","a,b,c = list(zip(*levels))\n","print(np.corrcoef(a,b), np.corrcoef(b,c), sep='\\n')\n","\n","ix = results_untrained.view(-1).argmax()\n","print(results_untrained.view(-1)[ix], within_epsilon[ix//12], prop_equal[(ix%12)//3], prop_filter[ix%3])\n","\n","# print(pruned_untrained.view(-1)[ix]/(4096*25088 + 4096*4096 + 4096*2 + 2))\n","# print(pruned_untrained.view(-1)[ix]/128780034)\n","# summary(model, (3,224,224))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"O0GjGtrP0sEi","colab_type":"code","outputId":"439a0c70-665f-48a9-aff4-293e552d4d59","executionInfo":{"status":"error","timestamp":1589318782812,"user_tz":240,"elapsed":485,"user":{"displayName":"Clark Benham","photoUrl":"","userId":"07053240447517243842"}},"colab":{"base_uri":"https://localhost:8080/","height":239}},"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","cord_list = (within_epsilon, prop_equal, prop_filter)\n","cord_tensor = torch.tensor(np.meshgrid(*cord_list))\n","cordinates = [cord_tensor[i] for i in range(3)]\n","axis_names = [\"Epsilon\", \"Proportion Equal\",  \"Proportion Filtered\"]\n","(results_trained, pruned_trained, time2) = (results_untrained, pruned_untrained, time1)\n","                 \n","for title, params, i in zip((\"Untrained Pruning\", \n","                          \"Trained Pruning\"), \n","                         ((results_untrained, pruned_untrained, time1), \n","                          (results_trained, pruned_trained, time2)),\n","                          (0,1)\n","                         ):\n","    fig1 = plt.figure(figsize=(15,20))\n","    # fig1, axes = plt.subplots(nrows = 2, ncols=3,figsize=(30,20))\n","    fig1.tight_layout()\n","    ttl = fig1.suptitle(title, size = 20)\n","    ttl.set_position([.5, 0.9])\n","    for c, j, t in zip(params, (0,1,2), (\"Accuracy\", \"% Pruned\", \"Time\")):\n","        # ax1 = axes[i,j]#fig1.add_subplot(s, projection='3d')\n","        ax1 = fig1.add_subplot(3, 1, j+1,  projection='3d')\n","        a = ax1.scatter(*cordinates, c=c.view(-1), s=24)\n","        fig1.colorbar(a)\n","        ax1.set_xlabel(\"Epsilon\")\n","        ax1.set_ylabel(\"Proportion Equal\")\n","        ax1.set_zlabel(\"Proportion Filtered\")\n","        ax1.set_title(t)\n","    plt.show()\n","\n","\n","for title, params in zip((\"Results for Untrained Pruning\", \n","                          \"Results for Trained Pruning\"), \n","                         ((results_untrained, pruned_untrained), \n","                          (results_trained, pruned_trained))\n","                         ):\n","    fig1 = plt.figure(figsize=(10,10))\n","    fig1.suptitle(title)\n","    for c, s2, y_name in zip(params, (0, 10), (\"Accuracy\", \"% Pruned\")):\n","        for axis_cord, s in zip(cordinates, (311, 312, 313)): \n","            dim = (s - 311)\n","            s += s2\n","            ax1 = fig1.add_subplot(s)\n","            # axis_sz = len(axis_cord)\n","            # num_rep = c.nelements()//axis_sz\n","            m_view = [len(i) for i in cordinates]\n","            m_view[dim] = -1\n","            # cor = torch.tensor(axis_cord).view(-1,-1,-1)\n","            # cor = cor.expand(*m_view)\n","            ax1.scatter(cordinates[dim], c.view(-1))\n","            ax1.set_xlabel(axis_names[dim])\n","            ax1.set_ylabel(y_name)\n","            # ax1.set_xticklabel([f\"\" for i in cordinates[dim])\n","        plt.show()"],"execution_count":7,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-ebea53950bdb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m                           \"Trained Pruning\"), \n\u001b[1;32m     10\u001b[0m                          ((results_untrained, pruned_untrained, time1), \n\u001b[0;32m---> 11\u001b[0;31m                           (results_trained, pruned_trained, time2)),\n\u001b[0m\u001b[1;32m     12\u001b[0m                           \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                          ):\n","\u001b[0;31mNameError\u001b[0m: name 'results_trained' is not defined"]}]},{"cell_type":"code","metadata":{"id":"kucbP5Elz9pX","colab_type":"code","colab":{}},"source":["\n","within_epsilon = [1, 2, 4, 8]\n","prop_equal = [0.5, 0.60, 0.7, 0.8]\n","prop_filter = [0.1, 0.2, 0.3]\n","\n","results_untrained = torch.zeros(4,4,3)\n","pruned_untrained = torch.zeros(4,4,3)\n","time1 = torch.zeros(4,4,3)\n","max_acc_untrained = 0\n","params_untrained = None\n","untrained_model = None\n","\n","sl = s.split(\"\\n\\n\\n\")\n","i = 0 \n","levels = []\n","for ie, e in enumerate(within_epsilon):\n","    # i = ie*12\n","    for ipE, pE in enumerate(prop_equal):\n","        for ipF, pF in enumerate(prop_filter):\n","            sub = sl[i].split(\"\\n\")[-1]\n","            sb = re.findall(\"(\\d+\\.\\d*)\", sub)\n","            results_untrained[ie, ipE, ipF] = float(sb[0])\n","            pruned_untrained[ie, ipE, ipF] = float(sb[1])\n","            time1[ie, ipE, ipF] = float(sb[2])\n","            levels.append([float(i) for i in re.findall(\"\"\"(\\d*\\.\\d*)\\% Pruned\"\"\", sl[i])])\n","            i += 1\n","a,b,c = list(zip(*levels))\n","print(np.corrcoef(a,b), np.corrcoef(b,c), sep='\\n')\n","\n","ix = results_untrained.view(-1).argmax()\n","print(results_untrained.view(-1)[ix], within_epsilon[ix//12], prop_equal[(ix%12)//3], prop_filter[ix%3])\n","\n","# print(pruned_untrained.view(-1)[ix]/(4096*25088 + 4096*4096 + 4096*2 + 2))\n","# print(pruned_untrained.view(-1)[ix]/128780034)\n","# summary(model, (3,224,224))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dVkpE2jyJHFT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":301},"outputId":"15984e27-5192-4e65-c000-08e80d654631","executionInfo":{"status":"ok","timestamp":1589224877527,"user_tz":240,"elapsed":327121,"user":{"displayName":"Clark Benham","photoUrl":"","userId":"07053240447517243842"}}},"source":["model = Vgg11bn()\n","print(\"Unpruned model Accuracy: \", check_accuracy(model, phase = 'test'))\n","\n","e, pE, pF = within_epsilon[ix//12], prop_equal[(ix%12)//3], prop_filter[ix%3]\n","default_params  = {'epsilon': e,\n","                'propEqual': pE,\n","                'propFilter': pF, \n","                'numResults': batch_size}\n","fill_buffers(model, num_passes=4)\n","prune_buffers(model)\n","print(\"Pruned model Accuracy: \", check_accuracy(model, phase = 'test'))\n","\n","\n","total_pruned(model, print_out = True)\n","criterion, optimizer_ft = model.critOpt()\n","train_model(model, dataloaders_dict, criterion, optimizer_ft, num_epochs=3, is_pruning=False)"],"execution_count":183,"outputs":[{"output_type":"stream","text":["33 Linear(in_features=25088, out_features=4096, bias=True) 79.03739929199219% Pruned\n","36 Linear(in_features=4096, out_features=4096, bias=True) 79.0262451171875% Pruned\n","39 Linear(in_features=4096, out_features=2, bias=True) 79.248046875% Pruned\n","Epoch 0/1\n","----------\n","train Loss: 0.6891 Acc: 0.5175\n","val Loss: 0.6764 Acc: 0.9085\n","\n","Epoch 1/1\n","----------\n","train Loss: 0.6760 Acc: 0.7061\n","val Loss: 0.6645 Acc: 0.9281\n","\n","Training complete in 5m 26s\n","Best val Acc: 0.928105\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["tensor(0.9281, dtype=torch.float64)"]},"metadata":{"tags":[]},"execution_count":183}]}]}